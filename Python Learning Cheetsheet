# Python Learning Cheetsheet
# Dictionary
  .keys()
  .values()
  .items()
# in Python, there is no native array data structure. So, we use Python lists instead of an array.
# A Pandas Series is a one-dimensional array of indexed data.

# Example: flatten the lists in dicts and create a new dict
  def most_common(menu):
    newlist = []
    for value in menu.values():
      newlist += value
    newdict = {}
    for item in newlist:
      if item not in newdict.keys():
        newdict[item] = 1
      else:
        newdict[item] += 1
    name = None 
    longest = -1
    for item in newdict.keys():
      if newdict[item] > longest:
        longest = newdict[item]
        name = item
    return "%s:%s" % (name, longest)
    
# PANDAS
## Basic Data Manipulation

0. Create a dataframe --> right = DataFrame({'key1': ['foo', 'foo', 'bar', 'bar'], 'key2': ['one', 'one', 'one', 'two'], 'rval': [4, 5, 6, 7]})
1. Select a specific row --> df.ix[1] or Select several rows --> df[:3]; Select a column --> df['colname'] or Select multiple colums --> df[['colname1','colname2']][14:18]
2. Random sample from dataframe: df.sample(n=5)
3. Sorting: df.sort_values(by='colname', ascending=False)[:10]
4. Subsetting
data[data.density > 100]

    .loc[] --> the loc attribute allows indexing and slicing that always references the explicit index
    .iloc[] --> the iloc attribute allows indexing and slicing that always references the implicit Python-style index

5. Partially matching text with .str.contains()

6. Groupby
   df.groupby(['LINCC_last_step','LINCC_last_vist_date'])['user_id'].count()
   .unstack()
   df.sort_values('start_date', ascending = True).groupby(['id']).cumcount()+1
   or
   df.groupby(['id'])['start_date'].rank(method='first',ascending=True)
7. Pivot Tables
   DataFrame.pivot_table(data, values=None, index=None, columns=None,
                      aggfunc='mean', fill_value=None, margins=False,
                      dropna=True, margins_name='All')
                      
   You can define how values are grouped by:
   index= (“Rows” in Excel)
   columns=
   We define which values are summarized by: values= the name of the column of values to be aggregated in the ultimate table, then grouped by the Index and Columns and aggregated according to the Aggregation Function
   We define how values are summarized by: aggfunc= (Aggregation Function) how rows are summarized, such as sum, mean, or count
   e.g. 
   flights_by_carrier = df.pivot_table(index='flight_date', columns='unique_carrier', values='flight_num', aggfunc='count').reset_index()

8. Common functions:  
   (1) df.country_code.fillna(df.user_country, inplace=True)
   (2) df=df.drop_duplicates(['user_id'], keep='last')
   (3) df=pd.merge(df1,df2,how='left',left_on='account_id',right_on='ads_account_id',indicator=True)
       df0=df[df['_merge']=='left_only']
   (4) df0=df.dropna(subset=['LINCC_last_step', 'BTC_last_page', 'Whitelist_type'], how='all')
   (5) replace value --> data.loc[data.company_name =='The Imprint Doctor','twitter_handle_lower'] = "theimprintdr"
   (6) pd.concat([dfA,dfB])
       df1.append(df2)

9. Functions
    Example:
    def filter_desktop_mobile(platform):
        if platform in mobile:
            return 'Mobile'
        elif platform == 'Desktop':
            return 'Desktop'
        else:
            return 'Not Known'

10. The .apply() method allows you to apply a function to a column of a DataFrame. 
e.g. data['platform'].apply(filter_desktop_mobile)
     data['delayed'] = data['arr_delay'].apply(lambda x: x > 0)

11. Resetting Index
    data2 = data1.copy()
    data2 = data2.reset_index()
    del data2['index']


## Modeling Steps
1. Load data:
   pd.read_csv('mattermark_adv_handle_df.csv',encoding='utf-8')
or pd.read_csv('.csv', thousands=",")
2. Data Quality Check:
   (0) data.describe()
   (1) Duplicates
        df.drop_duplicates(subset='company_id')
   (2) Missing Data
        df[pd.isnull(df.id)==False]
        data['employees_flag'] = data['employees'].apply(update_null)
        data.employees.fillna(0,inplace=True)
        
         # Functions
            ### Remove Columns
                def remove_col_from_df(df,col_list):
                    for col in col_list:
                        try:
                            df.drop(col,axis=1,inplace=True)
                        except:
                            print str(col) + ' not present to drop'
                    return df

            ### Change Null as 0 else 1
                def update_null(c):
                    if pd.isnull(c) == False:
                        return 1
                    else:
                        return 0

            ### Check NAs percentage in columns
                def get_NA_ratio (df, col_list):
                    for col in col_list:
                        try:
                            print str(col) + ": " + str(df[col].isnull().sum().astype(float)/len(df[col]))
                        except:
                            print str(col) + ' cannot get NAs'
    (3) Data Type + Encoding
        data['employees'] = data['employees'].astype(int)
        data.loc[data["has_mobile"] == "Yes", "has_mobile"] = 1
    
    (4) Scatter Plot + Histogram
        import matplotlib as mpl
        import matplotlib.pyplot as plt 
        import numpy

        #data['cached_growth_score_log'] = np.log(data['cached_growth_score'].astype('float'))
        #data['custom_score_log'] = np.log(data['custom_score'].astype('float'))
        plt.scatter(y=data.mindshare_score,x=data.mattermark_score)
        plt.show()
        
        bins = numpy.linspace(0, 2000, 10)
        plt.hist(data.cached_growth_score, bins, alpha=0.5)
        plt.show()
        
3. Model Building
   (1) Create a flag/label:
    pre_training_df['HighSpenderFlag'] = np.where(pre_training_df['total_spend'] >= 500,1,0)
   
   (2) Create training/test set:
    X = model_training_df.drop('HighSpenderFlag',axis=1)
    y = model_training_df['HighSpenderFlag']
    
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=0)
   
   (3) Perform feature selection and remove cols based on results:
    selector = SelectKBest(f_classif, k='all')
    selector.fit(X, y)
    print selector.pvalues_

    # Get the raw p-values for each feature, and transform from p-values into scores
    scores = -np.log10(selector.pvalues_)
    print scores

    predictors = list(X.columns)
    plt.bar(range(len(predictors)), scores)
    plt.xticks(range(len(predictors)), predictors, rotation='vertical')
    plt.show()
    print selector.pvalues_,selector.pvalues_<= 0.05
    
   (4) Model fitting 
       Logistic Regression: model1 = LogisticRegression(random_state=0)
                            model1.fit(X_train, y_train)
   
       score = model1.score(X_train, y_train)
       print("Train Score: %0.3f" % score)

       score = model1.score(X_test, y_test)
       print("Test Score: %0.3f" % score)
       
       Random Forest: model2 = RandomForestClassifier(bootstrap=True, random_state=0, n_estimators=30, min_samples_split=3, #min_samples_leaf = 500,
                                oob_score=True, class_weight={0:1,1:ratio} #
                                #class_weight = 'balanced'
                               )
                      model2.fit(X_train, y_train)
       score = model2.score(X_train, y_train)
       print("Train Score: %0.3f" % score)

       score = model2.score(X_test, y_test)
       print("Test Score: %0.3f" % score)   
       "Out-of-bag score: " --> model2.oob_score_
   
   (5) Model Validation   
       Confusion Matrix: 
          from sklearn.metrics import confusion_matrix

          y_pred = model.predict(X_test)
          cm = confusion_matrix(y_test, y_pred)

          index = ['Non-HighSpender', 'HighSpender']
          columns = ['predicted_Non-HighSpender', 'predicted_HighSpender']

          pd.DataFrame(cm, index=index, columns=columns)
       + Scores: classification_report(y_test, y_pred)
       
       ROC AUC Curve:
        # Determine the false positive and true positive rates
        fpr, tpr, _ = roc_curve(y_test, model.predict_proba(X_test)[:,1])

        # Calculate the AUC
        roc_auc = auc(fpr, tpr)
        print 'ROC AUC: %0.2f' % roc_auc

        # Plot of a ROC curve for a specific class
        plt.figure()
        plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)
        plt.plot([0, 1], [0, 1], 'k--')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title('ROC Curve')
        plt.legend(loc="lower right")
        plt.show()
        
      Adjust threshold:
        predictions = model.predict_proba(X_test)
        output= predictions >= 0.45
        output = output.astype(int)
        print confusion_matrix(y_test,output[:,1])
        
        print(classification_report(y_test, output[:,1]))
        
      Cross Validation
        cv_scores = CV.cross_val_score(model, X, y,cv=10)
        cv_predictions = CV.cross_val_predict(model5,X,y,cv=10)

        print metrics.accuracy_score(y, cv_predictions)

       #Precision and recall for expected outcomes
        print metrics.classification_report(y,cv_predictions)
       
        print("CV score: {:0.3f} +/- {:0.3f}".format(cvscores.mean(), cvscores.std()))
       
       #Leave One Out: 
        scores = cross_val_score(model, X, y, cv=LeaveOneOut(len(X)))
        scores.mean()
   
   (6) Variable Importance    
        from tabulate import tabulate
        headers = ["name", "score"]
        values = sorted(zip(X_train.columns, model2.feature_importances_), key=lambda x: x[1] * -1)
        print(tabulate(values, headers, tablefmt="plain"))
    
   (7) Grid Search
      from sklearn.model_selection import GridSearchCV


      param_grid = {'n_estimators': [30,40,50,80,100],
                    'min_samples_split': [2,3,4,5,10]}

      #grid = GridSearchCV(PolynomialRegression(), param_grid, cv=7)
      gsmodel = GridSearchCV(model2, param_grid, n_jobs=-1)
      gsmodel.fit(X_train, y_train)
      print("Best Model:")
      print(gsmodel.best_estimator_)
      print()
      print("Best Parameters:")
      print(gsmodel.best_params_)
      print()
      print("Best Score:")
      print(gsmodel.best_score_)
      
   (8) Prediction
      #Prediction data set
       X_predict_handles = model_predict_df.copy()
       proba_array_handles = model2.predict_proba(X_predict_handles)
       cols = ['<$500 Spend Probability', '>=$500 Spend Probability']
       proba_handles_df = pd.DataFrame(proba_array_handles,columns=cols)



## Plotting


## Sqlite
    import sqlite3

    conn = sqlite3.connect("mydatabase.db")
    cursor = conn.cursor()

    sql = """
    DELETE FROM albums
    WHERE artist = 'John Doe'
    """
    cursor.execute(sql)
    conn.commit()
    
## Hypothesis Test/Statistics
    import scipy.stats as stats
    One-sample T test (checks whether a sample mean differs from the population mean) --> stats.ttest_1samp(a= minnesota_ages,               # Sample data  
    popmean= population_ages.mean())  # Pop mean
    Two-sample T test (mean diff) --> stats.ttest_ind(a= minnesota_ages, b= wisconsin_ages, equal_var=False)    # Assume samples have equal variance?
    Paired T test --> stats.ttest_rel(a = before, b = after)
    
## Intro-lunch Exercise (Dictionary)
'''
Each of the functions below takes the statically defined dictionary 'MENU'
as input and should return (not print) a value that looks like what's shown
in the test.  The dictionary contains mappings of sandwiches and their
ingredients.  See the skeleton implementations for details on what each
function should determine.

>>> option_count(MENU)
26
>>> most_ingredients(MENU)
'California Burger: 9'
>>> most_common(MENU)
'mayonnaise: 22'
>>> unique_ingredients(MENU)
35
'''

def option_count(menu):
    '''How many options can I choose from for lunch?'''
    return len(menu)

def most_ingredients(menu):
    '''Which item on the menu has the most ingredients?
       How many does it have?'''
    name = None
    longest = -1
    for item, ingredients in menu.items():
      if len(ingredients) > longest:
        longest = len(ingredients)
        name = item
    return "%s:%s" % (name,longest)


def len_2(t):
  return len(t[1])

def most_ingredients(menu):
    '''Which item on the menu has the most ingredients?
       How many does it have?'''
    name, ingredients = max(menu.items(),key=len_2)
    return '%s:%s' % (name, len(ingredients))

def most_ingredients(menu):
  longest = -1
  name = None
  for key in menu.keys():
    if len(menu[key]) > longest:
      longest = len(menu[key])
      name = key
    #print key, len(menu[key]
  return name, longest


def most_common(menu):
    '''Which ingredient is the most common?  How many menu items does it
       appear on?'''
  ##Transfer to 1 list
  newlist = []
  for ingredients in menu.values():
    newlist += ingredients
    #newlist.extend(ingredients)
    #print ingredients
  ingredients = newlist
  # get the counts
  counts = {}
  for ingredient in ingredients:
    counts[ingredient] = counts.get(ingredient,0) + 1
  # pick the largest
  biggest = -1
  name = None
  for ingredient,count in counts.items():
    if count > biggest:
      biggest = count
      name = ingredient
  return '%s: %s' % (name, ingredient)

def most_common(menu):
  newlist = []
  for value in menu.values():
    newlist += value
  newdict = {}
  for item in newlist:
    if item not in newdict.keys():
      newdict[item] = 1
    else:
      newdict[item] += 1
  name = None 
  longest = -1
  for item in newdict.keys():
    if newdict[item] > longest:
      longest = newdict[item]
      name = item
  return "%s:%s" % (name, longest)

from collections import Counter
def most_common(menu):
    '''Which ingredient is the most common?  How many menu items does it
       appear on?'''
  ##Transfer to 1 list
  newlist = []
  for ingredients in menu.values():
    newlist += ingredients
    #newlist.extend(ingredients)
    #print ingredients
  ingredients = newlist
  counts = Counter(ingredients)
  return '%s:%s' % counts.most_common(1)[0]


def unique_ingredients(menu):
    '''How many different ingredients are there?'''
    newlist = []
    for ingredients in menu.values():
      newlist += ingredients
    return len(set(newlist))


MENU = { 'BBQ Beef': ['chopped beef steak', 'bbq sauce', 'mayonnaise'],
  'Bacon Burger': [ 'bacon',
                    'mustard',
                    'mayonnaise',
                    'onions',
                    'pickles',
                    'tomato',
                    'lettuce'],
  'California Burger': [ 'bacon',
                         'pepper jack',
                         'jalapenos',
                         'mustard',
                         'mayonnaise',
                         'onions',
                         'pickles',
                         'tomato',
                         'lettuce'],
  'California Chicken': [ 'chicken breast',
                          'mayonnaise',
                          'pepper jack',
                          'bacon',
                          'jalapenos',
                          'tomato',
                          'lettuce'],
  'Charbroiled Beef Hot Dog': [ 'mustard',
                                'mayonnaise',
                                'onions',
                                'pickles',
                                'tomato',
                                'lettuce'],
  'Charbroiled Chicken Breast': [ 'marinated filet chicken',
                                  'mayonnaise',
                                  'tomato',
                                  'lettuce'],
  'Club Sandwich': [ 'ham',
                     'turkey',
                     'bacon',
                     'cheese',
                     'mayonnaise',
                     'tomato',
                     'lettuce'],
  'Double Burger': [ 'mustard',
                     'mayonnaise',
                     'onions',
                     'pickles',
                     'tomato',
                     'lettuce'],
  'Garden Burger': ['veggie burger', 'onions', 'pickles', 'tomato', 'lettuce'],
  'Grilled Corned Beef': [ 'mustard',
                           'mayonnaise',
                           'onions',
                           'pickles',
                           'tomato',
                           'lettuce'],
  'Grilled Ham & Cheese': [ 'mustard',
                            'mayonnaise',
                            'onions',
                            'pickles',
                            'tomato',
                            'lettuce'],
  'Grilled Pastrami': [ 'mustard',
                        'mayonnaise',
                        'onions',
                        'pickles',
                        'tomato',
                        'lettuce'],
  'Guacamole Burger': [ 'avocado',
                        'mustard',
                        'mayonnaise',
                        'onions',
                        'pickles',
                        'tomato',
                        'lettuce'],
  'Guacamole Chicken': [ 'chicken breast',
                         'avocado',
                         'mayonnaise',
                         'onions',
                         'tomato'],
  'Hamburger Steak Sandwich': [ 'two beef patties',
                                'grilled onions',
                                'mushrooms',
                                'pepper',
                                'jack cheese on a roll'],
  'Hot Link': [ 'beef link',
                'mustard',
                'mayonnaise',
                'onions',
                'pickles',
                'tomato',
                'lettuce'],
  'Mushroom Burger': [ 'mushrooms',
                       'mustard',
                       'mayonnaise',
                       'onions',
                       'pickles',
                       'tomato',
                       'lettuce'],
  'Old Fashioned B.L.T': ['bacon', 'mayonnaise', 'tomato', 'lettuce'],
  'Pepper Steak': [ 'marinated beef',
                    'red pepper',
                    'onions',
                    'mushroom',
                    'tomato',
                    'lettuce'],
  'Philly Cheese Steak': [ 'chopped tender lean steak',
                           'mayonnaise',
                           'provolone cheese'],
  'Polish Sausage': ['mustard', 'mayonnaise', 'onions', 'tomato', 'lettuce'],
  'Roast Beef Melt': [ 'roast beef',
                       'choice of cheese',
                       'lettuce'],
  'Single Burger': [ 'mustard',
                     'mayonnaise',
                     'onions',
                     'pickles',
                     'tomato',
                     'lettuce'],
  'Steak Sandwich': [ 'sliced tender beef',
                      'mushrooms',
                      'grilled onions',
                      'mayonnaise',
                      'tomato',
                      'lettuce'],
  'Tuna Melt': [ 'fresh tuna',
                 'melted cheese',
                 'mayonnaise',
                 'onions',
                 'tomato',
                 'lettuce'],
  'Turkey Melt with Bacon': [ 'fresh cut turkey',
                              'bacon',
                              'melted cheese',
                              'mayonnaise']}

if __name__ == '__main__':
    import doctest
    doctest.testmod()
